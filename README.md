In this project, you will control a simulated and a real Turtlebot 3 burger mobile robot in a realistic challenging
environment, so as to make it navigate from one starting position to a goal position with different tasks to solve on
the path. The navigation should successively exploit:
• images obtained from a simulated/real camera to detect and follow some lines,
• a laser scan obtained from a simulated/real LDS to detected and avoid some obstacles,
• and finally both of them to navigate in a challenging environment where both sensors are required together.
The project will take the form of 3 successive challenges relying on the sensorimotor capabilities of the turtlebot, as
illustrated in the following Figure
![image](https://github.com/Svadilfvari/Self-Driving-robot-/assets/73406066/7dbb0d1b-34fc-46bd-b881-d495c1c192ec)
(This is an engoing project)
